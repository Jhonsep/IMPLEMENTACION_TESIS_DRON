# <img src="http://www.usb.ve/conocer/corporativa/archivos/logos/logo/logo.png" alt="Drone Tracking Badge" width="60"/> Anexos de Tesis: Redes Poco Profundas Autoajustadas para la Detecci贸n de Drones

Este repositorio alberga el **c贸digo fuente, modelos y *benchmarks*** resultantes de la investigaci贸n presentada como requisito parcial para optar al t铆tulo de **Ingeniero Electr贸nico** ante la ilustre **Universidad Sim贸n Bol铆var**.

El contenido aqu铆 expuesto corresponde a la implementaci贸n pr谩ctica de la tesis titulada:

### **"Redes Poco Profundas Autoajustadas para la Detecci贸n de Drones"**

---

# <img src="https://www.thiings.co/_next/image?url=https%3A%2F%2Flftz25oez4aqbxpq.public.blob.vercel-storage.com%2Fimage-68rfbsUnBY2TBf4kEsCmMWHvcnSnKO.png&w=500&q=75" alt="Drone Tracking Badge" width="60"/> Sistema de Rastreo y Detecci贸n de Drones (A1 + A2)

Este proyecto implementa una **doble arquitectura de red neuronal (A1 y A2)** para el **rastreo de un objetivo** (basado en la matriz espacio-tiempo o STM) y la **clasificaci贸n binaria** (Drone/NoDrone) dentro de una regi贸n de inter茅s (ROI) en tiempo real, utilizando **OpenCV** y **TensorFlow/Keras**.

---

##  Estructura del Proyecto

* `rastreo.py`: Implementaci贸n base solo para la **arquitectura A1 (Rastreo por offset)**.
* `rastreo_deteccion(A1_A2).py`: Implementaci贸n de la *pipeline* completa **A1 (Rastreo) + A2 (Detecci贸n/Clasificaci贸n)**.
* `test.py`: Versi贸n de la *pipeline* A1+A2 con adici贸n de **medici贸n de rendimiento** (latencias, FPS) y generaci贸n de resumen/CSV.
* `benchmark_times.csv`: Ejemplo de archivo CSV generado por `test.py` con m茅tricas de rendimiento por *frame*.
* `models/`: Directorio que contiene los modelos preentrenados de Keras (`.keras`).
    * `OTA_drone_model_E3_T2.keras` (Modelo A1: *Offset Tracking Autoencoder*)
    * `recognizer_dron_model_T1.keras` (Modelo A2: Reconocimiento/Clasificaci贸n)
* `images/`: Directorio para im谩genes de ejemplo o referencias (como capturas de pantalla del HUD o el ROI).

---

##  Requisitos e Instalaci贸n

Para ejecutar los *scripts*, necesitar谩s las siguientes librer铆as de Python.

```bash
pip install opencv-python tensorflow numpy
```

Aseg煤rate de que tus archivos de modelo se encuentren en el directorio `./models/` tal como est谩n referenciados en los *scripts*.

---

## 锔 Configuraci贸n y Uso

### Modelos y Configuraci贸n

Los par谩metros principales se definen al inicio de cada *script*. **Aseg煤rate de ajustar:**

| Par谩metro | Archivo(s) | Descripci贸n |
| --- | --- | --- |
| `A1_MODEL_PATH` | Todos | Ruta al modelo de rastreo (A1). |
| `A2_MODEL_PATH` | A1_A2, test | Ruta al modelo de clasificaci贸n (A2). |
| `CAMERA_INDEX` | Todos | ndice de la c谩mara web a usar (t铆picamente 0 o 1). |
| `ROI_H`, `ROI_W` | Todos | Dimensiones de la Regi贸n de Inter茅s (ROI). |
| `CONFIDENCE` | A1_A2, test | Umbral de confianza para la clasificaci贸n (A2). |
| `DAMPERING` | A1_A2, test | N煤mero de detecciones consecutivas requeridas para confirmar el objeto (amortiguaci贸n). |

Exportar a Hojas de c谩lculo

### Ejecuci贸n con Medici贸n de Rendimiento

Utiliza `test.py` para medir latencias por etapa (`capture`, `pre`, `A1`, `stm`, `A2`, `render`, `loop`) y obtener un resumen de FPS.

Bash

`python test.py`

Al finalizar, se imprimir谩 un resumen de latencias y se crear谩 (opcionalmente) un archivo CSV con m茅tricas por cada *frame*.

---

##  Arquitectura

El sistema opera con dos redes neuronales secuenciales:

1. **A1 (Offset Tracking Autoencoder):** Recibe la imagen de bordes (Canny) de la ROI actual y la matriz espacio-tiempo (STM) del movimiento anterior. Predice un peque帽o **offset (dx, dy)** para recentrar la ROI sobre el objetivo.
2. **A2 (Reconocimiento/Clasificaci贸n):** Recibe el *crop* de la imagen a color de la ROI. Clasifica el contenido como **Drone** o **NoDrone** y aplica amortiguaci贸n para estabilidad.
